{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Check if GPU is available and use it, otherwise fallback to CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the DehazeNet model architecture (same as during training)\n",
    "class DehazeNet(torch.nn.Module):\n",
    "    def __init__(self):  # Corrected the method name\n",
    "        super(DehazeNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "# Load the trained model (update the path to where you saved the model on your laptop)\n",
    "model = DehazeNet().to(device)\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(\"D:\\\\Mini project Git\\\\Dehazing-and-Human-Detection-Project\\\\Dehazing_model\\\\dehaze_model.pth\"))  # Path to the saved model file\n",
    "    print(\"Model loaded successfully.\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error loading the model: {e}\")\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define the image transformation (same as used during training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Reverse the normalization after prediction\n",
    "def reverse_normalization(tensor):\n",
    "    return tensor * 0.5 + 0.5  # Reverse normalization applied during training\n",
    "\n",
    "# Function to process frames through the model\n",
    "def process_frame(frame):\n",
    "    # Ensure the input frame is in the correct format\n",
    "    if frame is None or not isinstance(frame, np.ndarray):\n",
    "        raise ValueError(\"Invalid frame input. Ensure it's a valid NumPy array.\")\n",
    "\n",
    "    # Preprocess the frame\n",
    "    input_frame = transform(frame).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        output = model(input_frame).cpu()\n",
    "\n",
    "    # Postprocess the output\n",
    "    output_frame = output.squeeze(0).permute(1, 2, 0).numpy()  # CHW to HWC\n",
    "    output_frame = reverse_normalization(output_frame)  # Reverse normalization\n",
    "    output_frame = np.clip(output_frame * 255, 0, 255).astype(np.uint8)  # Ensure valid pixel range\n",
    "    return output_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the webcam feed (ensure your webcam is available and connected)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame from BGR to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Dehaze the frame using the trained model\n",
    "    dehazed_frame = process_frame(frame_rgb)\n",
    "\n",
    "    # Convert the dehazed frame back to BGR for OpenCV\n",
    "    dehazed_frame_bgr = cv2.cvtColor(dehazed_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Display the dehazed frame\n",
    "    cv2.imshow(\"Dehazed Frame\", dehazed_frame_bgr)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
